---
title: "[대용량 이미지 처리] h5py를 활용한 빠른 속도의 이미지 파일 stack"
date: 2021-05-17 12:50:00 -0400
categories: 
- 이미지분석
- Coco
- ImageNet
- h5py
- 대용량이미지
- 딥러닝
---

# [대용량 이미지 처리] h5py를 활용한 빠른 속도의 이미지 파일 stack

coco 데이터를 활용해서 이미지 딥러닝 분석을 진행하고 있던 도중, 로컬 컴퓨터의 메모리 한계를 겪었습니다.

그래서 데이터를 나눠서 순서대로 불러와 모델에 넣고 drop하는 방법이 없을까 검색하던 중 h5py라는 방법을 알게되어 공유합니다.

numpy나 pandas를 이용해 데이터 전처리를 진행하는 경우 모든 데이터를 메모리에 올린 상태에서 진행해야하기 때문에, 메모리 부족현상이 있을 수 있습니다.

하지만 h5py는 전체 데이터를 불러오지 않고 일부만 불러와서 전처리하는 것도 가능하며,

제목과 같이 이미지를 stack할 때 전체 stack이 메모리에 올라가 있지 않아도 된다는 장점이 있습니다.

아래 공유된 코드 이외에도 group, attr 등을 활용하는 방법도 있으니 자세한 내용은 짧게 코드를 공유합니다.

# h5py 파일 생성

with를 사용해 h5py 파일을 생성한다.

'''python
with h5py.File('sample_h5py.h5', 'w') as f:
    f.create_dataset('group1')
'''

## 이미지 파일을 개별적으로 불러온 후 h5py파일에 stack 하는 방법

'padding'과 img_to_tensor는 user_defined 함수이고, img를 path에서 불러와서 img로 넣어주고, img_ds에 coco_toy_data - images를 할당해주고 img_ds의 index를 활용해 img_ds에 불러온 img를 하나씩 넣어주는 방식입니다.

'''python
import h5py

with h5py.File('coco_toy_data.h5', 'w') as f:
    img_ds = f.create_dataset('images', shape = (len(toy_img_path), b_w, b_h, 3), dtype = int)
    for i, path in tqdm(enumerate(toy_img_path), total = len(toy_img_path)):
        img = padding(img_to_tensor(path))
        img_ds[i:i+1:, :, :] = img
'''

하지만 이 방법은 엄청난 크기의 파일 용량을 차지합니다.

실제로 640 x 640 x 3 사이즈의 이미지 16만 장을 해당 코드를 통해 합쳐주는 과정에서 7만 장 부근에서 처음보는 error가 발생하여, 

구글에 검색해보니 컴퓨터 디스크 메모리 부족이라하여 디스크 메모리를 보니 실제로 7GB가 남아있었습니다.

h5 파일을 확인해보니 320기가...였습니다.

따라서 파일을 압축하여 저장하는 방법을 찾아냈습니다.

## 이미지 파일을 개별적으로 불러온 후 h5py파일에 압축하여 stack 하는 방법

코드에는 create_dataset의 paramter중 compression과, compression_opt가 추가된 것 밖에는 없습니다.

실제 압축이 되었는지 확인하기 위해 100개의 640 x 640 x 3의 이미지로 테스트 한 결과 압축하기 전에는 468MB였던 파일이 압축 후에는 991KB로 줄어있었습니다.

불러와서 확인한 결과 차이가 없는 것 역시 확인했습니다.

다만 속도가 1/10으로 줄어드는 단점이 있었으나 용량이 확실히 개선되었기 때문에 압축하는 방법을 추천합니다.

'compression_opt' 값이 클 수록 압축률이 높아지고 속도는 느려지니 참고하면 좋을 것 같습니다.

'''python
import h5py

with h5py.File('coco_toy_data.h5', 'w') as f:
    img_ds = f.create_dataset('images', shape = (len(toy_img_path), b_w, b_h, 3), dtype = int,
    compression = 'gzip', compression_opt = 9)
    for i, path in tqdm(enumerate(toy_img_path), total = len(toy_img_path)):
        img = padding(img_to_tensor(path))
        img_ds[i:i+1:, :, :] = img
'''



기타 상세한 내용은 [h5py 페이지](https://www.h5py.org/)를 참고하면 좋을 것 같다.
